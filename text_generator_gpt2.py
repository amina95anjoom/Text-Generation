# -*- coding: utf-8 -*-
"""Text generator_gpt2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e8CmNkbMKy4FYztq66gWdfwcNrjlrKeR
"""

!pip install -q gradio

"""# New section"""

!pip install -q git+https://github.com/huggingface/transformers.git

import gradio as gr
import tensorflow as tf

from transformers import GPT2Tokenizer,TFGPT2LMHeadModel

#tokenizer=AutoTokenizer.from_pretrained('t5-base')
tokenizer=GPT2Tokenizer.from_pretrained("gpt2")
model=TFGPT2LMHeadModel.from_pretrained("gpt2",pad_token_id=tokenizer.eos_token_id)
#model.from_pretrained(self=SimpleT5,model_type='t5', model_name='t5-base')

def generate_Text(inp):
    input_ids=tokenizer.encode(inp,return_tensors='tf')
    beam_output=model.generate(input_ids,max_length=500,num_beams=5,no_repeat_ngram_size=3,early_stopping=False)
    output=tokenizer.decode(beam_output[0],skip_special_tokens=True,clean_up_tokenization_spaces=True)
    return ".".join(output.split(".")[:-1])+"."

output_text=gr.components.Textbox()
gr.Interface(generate_Text,"textbox",output_text,description="Text generated by gpt2").launch(share=True)